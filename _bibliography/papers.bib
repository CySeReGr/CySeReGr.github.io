---
---
@INPROCEEDINGS{10063568,
  author={Alalmaie, Abeer Z. and Nanda, Priyadarsi and He, Xiangjian},
  booktitle={2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  title={Zero Trust-NIDS: Extended Multi-View Approach for Network Trace Anonymization and Auto-Encoder CNN for Network Intrusion Detection},
  year={2022},
  volume={},
  number={},
  pages={449-456},
  doi={10.1109/TrustCom56396.2022.00069},
  selected={true}}

@article{QASHLAN202449,
title = {Differential privacy model for blockchain based smart home architecture},
journal = {Future Generation Computer Systems},
volume = {150},
pages = {49-63},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23003102},
author = {Amjad Qashlan and Priyadarsi Nanda and Manoranjan Mohanty},
keywords = {Smart home, Blockchain, Differential privacy, Membership inference attack, Internet of Things, Edge computing},
abstract = {Secure and private communications using the Internet of Things (IoT) pose several challenges for smart home systems. In particular, data collected from IoT devices comprise sensitive personal information such as biomedical data, financial data, and location and activity data. Recent research looks into the use of blockchain in smart home systems, protecting the privacy of the data in use. Such solutions need to address the issue of privacy using a formal and mathematical model for data privacy due to the vulnerability associated with privacy-preserving blockchain networks. In the present paper, our approach aims to provide a privacy-preserving data aggregation mechanism in the context of Smart Homes that agree to contribute their data to a cloud server using machine learning to improve services for home users. We propose the use of differential privacy, a powerful concept in privacy preserving schemes to provide formal assurances about how much information is leaked using a privacy budget. The main purpose of using such a privacy-preserving scheme is to limit what can be inferred about individual training data from the model. Our techniques use a R′enyi differential privacy (RDP) machine learning scheme and are based on a variant of the stochastic gradient descent function. The performance of our proposed framework is evaluated using three public datasets: UNSW-NB15, NSL-KDD, and ToN-IoT datasets. Our findings show that differential private models can provide privacy protection against attackers by sacrificing a substantial amount of model utility. Therefore, we propose an empirical value of ϵ, that can optimally balances utility and privacy for the current smart home scenario datasets.}
}
